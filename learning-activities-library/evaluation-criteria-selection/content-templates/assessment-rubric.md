# Assessment Rubric: Evaluation Criteria Selection Activity

## Overview

This rubric evaluates student performance on the Azure AI Foundry Evaluation Criteria Selection activity. The assessment focuses on students' ability to analyze business scenarios, understand evaluation metrics, and make strategic decisions about AI evaluation approaches.

## Scoring Scale

- **4 - Excellent (90-100%)**: Exceeds expectations, demonstrates mastery
- **3 - Proficient (80-89%)**: Meets expectations, shows competence  
- **2 - Developing (70-79%)**: Partially meets expectations, shows understanding with gaps
- **1 - Beginning (60-69%)**: Does not meet expectations, shows limited understanding
- **0 - Incomplete (0-59%)**: No evidence of understanding or incomplete work

## Assessment Criteria

### 1. Business Scenario Analysis (25 points)

#### Excellent (23-25 points)
- **Comprehensive Objective Identification**: Identifies all major business objectives with nuanced understanding of priorities and relationships
- **Stakeholder Analysis**: Demonstrates deep understanding of different stakeholder perspectives and their influence on AI evaluation needs
- **Context Understanding**: Shows sophisticated grasp of industry context, challenges, and constraints that affect metric selection
- **Success Metrics Recognition**: Clearly connects business success indicators to potential AI evaluation metrics

#### Proficient (20-22 points)
- **Clear Objective Identification**: Identifies most major business objectives with good understanding of their importance
- **Stakeholder Recognition**: Shows good understanding of key stakeholders and their general interests in AI performance
- **Context Awareness**: Demonstrates solid understanding of business context and its implications for evaluation
- **Success Connection**: Makes appropriate connections between business success and AI evaluation needs

#### Developing (18-19 points)
- **Basic Objective Identification**: Identifies some business objectives but may miss key priorities or relationships
- **Limited Stakeholder Analysis**: Shows basic awareness of stakeholders but limited understanding of their specific concerns
- **Surface Context Understanding**: Demonstrates general understanding of business context but misses important nuances
- **Weak Success Connections**: Makes some connections between business and evaluation needs but lacks depth

#### Beginning (15-17 points)
- **Minimal Objective Recognition**: Identifies few or superficial business objectives
- **Poor Stakeholder Understanding**: Shows little awareness of stakeholders beyond obvious ones
- **Limited Context Grasp**: Demonstrates minimal understanding of business context and its evaluation implications
- **No Success Connections**: Fails to connect business success indicators to evaluation needs

### 2. Azure AI Foundry Metrics Knowledge (20 points)

#### Excellent (18-20 points)
- **Comprehensive Category Understanding**: Demonstrates deep knowledge of all metric categories and their purposes
- **Detailed Metric Knowledge**: Shows understanding of specific metrics, their applications, and complementary relationships
- **Application Awareness**: Clearly understands when and why different metrics are most valuable
- **Nuanced Differentiation**: Can articulate subtle differences between similar metrics and their trade-offs

#### Proficient (16-17 points)
- **Good Category Knowledge**: Shows solid understanding of most metric categories and general purposes
- **Adequate Metric Familiarity**: Demonstrates reasonable knowledge of specific metrics and their basic applications
- **Appropriate Application**: Generally understands when different metrics are useful
- **Basic Differentiation**: Can distinguish between different types of metrics with some sophistication

#### Developing (14-15 points)
- **Limited Category Understanding**: Shows partial knowledge of metric categories with some confusion
- **Surface Metric Knowledge**: Demonstrates basic familiarity with metrics but limited understanding of applications
- **Unclear Application Logic**: Shows uncertainty about when to use different metrics
- **Poor Differentiation**: Struggles to distinguish between similar metrics or understand trade-offs

#### Beginning (12-13 points)
- **Minimal Category Knowledge**: Shows little understanding of metric categories and their purposes
- **Inadequate Metric Familiarity**: Demonstrates very limited knowledge of specific metrics
- **No Application Logic**: Cannot articulate when or why to use different metrics
- **No Differentiation**: Cannot distinguish between different types of metrics

### 3. Metric Selection Strategy and Reasoning (25 points)

#### Excellent (23-25 points)
- **Strategic Alignment**: Metric selections directly and clearly support identified business objectives
- **Sophisticated Reasoning**: Provides thoughtful, detailed justification that considers multiple factors and trade-offs
- **Balanced Coverage**: Selects metrics that provide comprehensive evaluation coverage across relevant dimensions
- **Risk Consideration**: Demonstrates awareness of potential risks and how selected metrics address them

#### Proficient (20-22 points)
- **Good Alignment**: Metric selections generally support business objectives with clear connections
- **Solid Reasoning**: Provides reasonable justification for selections with consideration of key factors
- **Adequate Coverage**: Selects metrics that provide good evaluation coverage with minor gaps
- **Basic Risk Awareness**: Shows some consideration of risks and mitigation through metric selection

#### Developing (18-19 points)
- **Partial Alignment**: Some metric selections align with business objectives but connections may be weak
- **Limited Reasoning**: Provides basic justification but may lack depth or miss important considerations
- **Uneven Coverage**: Metric selection provides partial coverage but may have significant gaps
- **Minimal Risk Consideration**: Shows little awareness of risks or how metrics address them

#### Beginning (15-17 points)
- **Poor Alignment**: Metric selections do not clearly support business objectives
- **Weak Reasoning**: Provides minimal or unclear justification for selections
- **Inadequate Coverage**: Metric selection provides poor evaluation coverage with major gaps
- **No Risk Awareness**: Shows no consideration of risks or mitigation strategies

### 4. Expert Comparison and Learning (15 points)

#### Excellent (14-15 points)
- **Thoughtful Analysis**: Provides sophisticated analysis of differences between personal and expert selections
- **Learning Integration**: Demonstrates clear learning from expert feedback and incorporates insights
- **Perspective Recognition**: Shows understanding of different valid approaches and why experts might choose differently
- **Reflective Insight**: Exhibits metacognitive awareness of own selection process and areas for improvement

#### Proficient (12-13 points)
- **Good Analysis**: Provides reasonable analysis of differences with expert selections
- **Clear Learning**: Shows evidence of learning from expert feedback
- **Alternative Recognition**: Recognizes that different approaches can be valid
- **Some Reflection**: Demonstrates some self-awareness about selection process

#### Developing (11 points)
- **Basic Analysis**: Provides superficial analysis of differences with limited insight
- **Limited Learning**: Shows minimal learning from expert feedback
- **Rigid Thinking**: Has difficulty accepting alternative approaches or perspectives
- **Little Reflection**: Shows minimal self-awareness or reflection on process

#### Beginning (9-10 points)
- **No Analysis**: Provides no meaningful analysis of expert comparison
- **No Learning Evidence**: Shows no evidence of learning from expert feedback
- **Dismissive Attitude**: Dismisses expert recommendations without consideration
- **No Reflection**: Shows no self-awareness or reflection on learning process

### 5. Application and Future Planning (15 points)

#### Excellent (14-15 points)
- **Realistic Implementation**: Demonstrates understanding of practical considerations for metric implementation
- **Evolution Awareness**: Shows sophisticated understanding of how metric priorities might change over time
- **Stakeholder Sensitivity**: Recognizes how different stakeholders might prioritize metrics differently
- **Professional Application**: Clearly connects learning to real-world AI project scenarios

#### Proficient (12-13 points)
- **Good Implementation Understanding**: Shows reasonable awareness of practical implementation considerations
- **Basic Evolution Concepts**: Understands that metric priorities might change but with limited sophistication
- **Stakeholder Recognition**: Shows awareness that different stakeholders have different priorities
- **Clear Application**: Makes good connections between learning and professional scenarios

#### Developing (11 points)
- **Limited Implementation Awareness**: Shows minimal understanding of practical considerations
- **Static Thinking**: Little recognition that metric priorities might evolve
- **Limited Stakeholder Perspective**: Shows minimal awareness of different stakeholder priorities
- **Weak Application**: Makes few or unclear connections to real-world applications

#### Beginning (9-10 points)
- **No Implementation Consideration**: Shows no awareness of practical implementation challenges
- **No Evolution Understanding**: No recognition that priorities might change over time
- **Single Perspective**: Shows no awareness of different stakeholder viewpoints
- **No Professional Connection**: Cannot connect learning to real-world scenarios

## Holistic Performance Indicators

### Exceptional Performance (95-100%)
- Demonstrates mastery of business-technology alignment principles
- Shows sophisticated understanding of evaluation strategy in AI deployment
- Exhibits professional-level decision-making skills
- Demonstrates clear readiness for advanced AI project roles

### Strong Performance (85-94%)
- Shows solid competence in metric selection and business alignment
- Demonstrates good understanding of evaluation concepts
- Exhibits developing professional judgment
- Shows readiness for guided AI evaluation work

### Acceptable Performance (75-84%)
- Shows basic competence with some guidance needed
- Demonstrates foundational understanding of key concepts
- Exhibits some professional judgment with room for growth
- Shows readiness for supervised AI evaluation tasks

### Needs Improvement (65-74%)
- Shows limited competence requiring significant guidance
- Demonstrates partial understanding with major gaps
- Exhibits minimal professional judgment
- Needs additional learning before AI evaluation work

### Unsatisfactory Performance (Below 65%)
- Shows inadequate competence for the learning level
- Demonstrates insufficient understanding of core concepts
- Exhibits poor professional judgment
- Requires remediation before proceeding

## Feedback Guidelines

### Strengths Recognition
Highlight specific examples where students:
- Made insightful connections between business needs and metrics
- Demonstrated sophisticated reasoning about trade-offs
- Showed learning and adaptation from expert feedback
- Applied concepts to novel scenarios

### Improvement Areas
Focus on:
- **Specificity**: Encourage more detailed reasoning and justification
- **Business Focus**: Help students maintain business-first perspective
- **Multiple Perspectives**: Encourage consideration of different stakeholder viewpoints
- **Strategic Thinking**: Guide students toward long-term and system-level thinking

### Development Recommendations

#### For High Performers
- Encourage leadership in peer discussions
- Assign advanced scenarios or metric customization tasks
- Invite to share insights with struggling students
- Provide opportunities for teaching or mentoring

#### For Developing Students
- Provide additional practice with guided examples
- Pair with stronger students for collaborative learning
- Offer simplified scenarios to build confidence
- Schedule individual consultation sessions

#### For Struggling Students
- Review prerequisite concepts and knowledge
- Provide step-by-step guidance through the selection process
- Use concrete examples and analogies
- Consider alternative assessment formats if appropriate

## Grade Calculation

**Total Points: 100**

| Criterion | Weight | Points |
|-----------|--------|---------|
| Business Scenario Analysis | 25% | /25 |
| Azure AI Foundry Metrics Knowledge | 20% | /20 |
| Metric Selection Strategy and Reasoning | 25% | /25 |
| Expert Comparison and Learning | 15% | /15 |
| Application and Future Planning | 15% | /15 |
| **Total Score** | **100%** | **/100** |

## Grade Scale

- A: 90-100% (Excellent)
- B: 80-89% (Proficient)  
- C: 70-79% (Developing)
- D: 60-69% (Beginning)
- F: Below 60% (Incomplete)

## Common Assessment Challenges

### Challenge: Students focus on technical metrics without business justification
**Instructor Response**: Redirect to business objectives and ask "How does this metric help achieve the stated business goals?"

### Challenge: Students provide superficial reasoning
**Instructor Response**: Ask follow-up questions like "What would happen if this metric improved but others stayed the same?"

### Challenge: Students dismiss expert recommendations defensively
**Instructor Response**: Frame as learning opportunity: "Experts bring different experiences and constraints. What can we learn from their perspective?"

### Challenge: Students struggle to differentiate between similar metrics
**Instructor Response**: Provide specific scenarios where each metric would be more valuable and have students explain the differences

## Accommodation Guidelines

### For Students with Learning Differences
- Allow additional time for scenario analysis and reflection
- Provide visual aids or diagrams for metric relationships
- Offer alternative formats for written responses (oral, video, etc.)
- Break complex scenarios into smaller components

### For English Language Learners
- Provide glossary of business and technical terms
- Allow use of translation tools for complex vocabulary
- Accept responses that demonstrate understanding even with language errors
- Offer native language resources where available

### For Students with Technology Challenges
- Provide printed worksheets as backup
- Ensure alternative access methods for interactive components
- Allow completion in multiple sessions if needed
- Provide technical support resources

This comprehensive rubric ensures fair, consistent, and meaningful assessment of student learning while providing clear guidance for both instructors and students on expectations and improvement opportunities.