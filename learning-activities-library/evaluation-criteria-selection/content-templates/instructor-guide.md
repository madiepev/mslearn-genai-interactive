# Instructor Guide: Evaluation Criteria Selection Activity

## Activity Overview

The Evaluation Criteria Selection activity teaches students to analyze business scenarios and select appropriate Azure AI Foundry evaluation metrics. Students practice the critical skill of aligning evaluation criteria with business objectives, which is essential for successful AI deployment.

## Learning Objectives

By the end of this activity, students will be able to:

1. **Analyze Business Context**: Identify key business objectives, stakeholder needs, and success metrics from scenario descriptions
2. **Understand Azure AI Foundry Metrics**: Demonstrate knowledge of different evaluation metric categories and their purposes
3. **Align Metrics with Objectives**: Select evaluation criteria that directly support specific business goals and use cases
4. **Justify Selection Rationale**: Explain why chosen metrics are appropriate for given business scenarios
5. **Compare with Expert Recommendations**: Evaluate their selections against expert recommendations and understand alternative perspectives

## Pedagogical Framework

### Learning Theory Foundation
- **Experiential Learning**: Students learn through hands-on practice with realistic business scenarios
- **Social Learning**: Comparison with expert selections provides modeling and feedback
- **Constructivist Approach**: Students build understanding by making connections between business needs and technical metrics
- **Reflective Practice**: Post-selection analysis encourages metacognitive thinking

### Bloom's Taxonomy Alignment
- **Knowledge**: Recognize different types of Azure AI Foundry metrics
- **Comprehension**: Understand the purpose and application of each metric category
- **Application**: Apply metric selection principles to specific business scenarios
- **Analysis**: Break down business scenarios to identify key evaluation requirements
- **Synthesis**: Combine multiple metrics to create comprehensive evaluation approaches
- **Evaluation**: Judge the effectiveness of different metric combinations

## Pre-Activity Preparation

### Prerequisites
Students should have completed:
- Introduction to AI evaluation concepts
- Overview of Azure AI Foundry platform
- Basic understanding of business metrics and KPIs
- Familiarity with different AI application types (sales, support, content generation)

### Instructor Preparation Checklist
- [ ] Review all business scenarios for accuracy and relevance
- [ ] Verify Azure AI Foundry metrics are current and correctly described
- [ ] Test activity functionality across different devices and browsers
- [ ] Prepare additional scenarios for extended practice if needed
- [ ] Set up assessment rubric and grading criteria
- [ ] Plan debriefing discussion questions

### Technical Setup
- Ensure stable internet connection for all participants
- Test activity on multiple browser types and versions
- Verify mobile responsiveness for BYOD environments
- Prepare backup activities in case of technical difficulties
- Set up screen sharing capability for demonstration

## Activity Facilitation Guide

### Introduction Phase (5 minutes)

#### Opening Script
"Today we're going to explore one of the most critical decisions in AI deployment: selecting the right evaluation criteria. You'll analyze real business scenarios and choose Azure AI Foundry metrics that align with specific objectives. This skill is essential because the wrong metrics can lead to AI systems that perform well in testing but fail in production."

#### Key Concepts to Emphasize
1. **Business-First Approach**: Metrics should serve business objectives, not just technical requirements
2. **Stakeholder Perspective**: Different stakeholders may prioritize different aspects of AI performance
3. **Trade-off Awareness**: No single metric captures everything; selections involve strategic trade-offs
4. **Context Dependency**: The same AI application may need different metrics in different business contexts

#### Demonstration (Optional)
Walk through one scenario example:
1. Read scenario aloud
2. Identify key business objectives
3. Discuss potential stakeholder concerns
4. Model the selection thought process
5. Show how to interpret expert feedback

### Active Learning Phase (15 minutes)

#### Student Workflow
1. **Scenario Analysis** (3 minutes)
   - Read business scenario carefully
   - Identify primary business objectives
   - Note key stakeholders and their concerns
   - Consider success metrics and challenges

2. **Metric Exploration** (5 minutes)
   - Browse available Azure AI Foundry metrics
   - Read descriptions and business impact statements
   - Consider metric categories and complementary relationships
   - Think about coverage and balance

3. **Selection Process** (4 minutes)
   - Choose 3 metrics that best align with business objectives
   - Consider diversity across categories
   - Balance immediate needs with long-term goals
   - Document selection reasoning (mental notes)

4. **Expert Comparison** (3 minutes)
   - Review expert recommendations
   - Compare with personal selections
   - Read expert reasoning and avoided metrics
   - Reflect on differences and similarities

#### Instructor Monitoring
- Circulate to observe student thought processes
- Note common misconceptions or difficulties
- Provide hints for students who seem stuck
- Encourage students to vocalize their reasoning
- Address technical issues promptly

#### Common Student Challenges and Responses

**Challenge**: Students select metrics that sound impressive but don't align with scenario
**Response**: "Think about what success looks like for this specific business. What would stakeholders actually measure?"

**Challenge**: Students choose all metrics from one category
**Response**: "Consider what happens if you optimize only for [category]. What other aspects might suffer?"

**Challenge**: Students can't decide between similar metrics
**Response**: "Look at the 'best for' applications and 'complementary metrics'. Which combination gives you the best coverage?"

**Challenge**: Students dismiss expert recommendations too quickly
**Response**: "Expert selections often reflect real-world constraints you might not have considered. What factors might explain their choices?"

### Reflection and Debriefing (10 minutes)

#### Individual Reflection Questions
1. What was your primary selection strategy? Did it change during the activity?
2. Which aspect of the business scenario most influenced your choices?
3. How did your selections compare with expert recommendations? What surprised you?
4. What would you do differently if you encountered a similar scenario in the workplace?

#### Group Discussion Topics
1. **Selection Strategies**: Have students share their approaches and reasoning
2. **Metric Trade-offs**: Discuss what happens when you optimize for one metric at the expense of others
3. **Real-world Applications**: Connect scenarios to students' actual work or career interests
4. **Expert Perspectives**: Explore why experts might choose differently than students
5. **Implementation Challenges**: Discuss practical considerations for implementing chosen metrics

#### Advanced Discussion Questions
- How might metric priorities change over time as an AI system matures?
- What role should user feedback play in metric selection and weighting?
- How would you handle disagreement between stakeholders about metric priorities?
- What additional metrics might be needed for specific industries or regulations?

## Assessment Strategy

### Formative Assessment (During Activity)
- **Observation**: Monitor student engagement and thought processes
- **Quick Checks**: Ask students to explain their reasoning verbally
- **Peer Discussion**: Encourage students to discuss selections with neighbors
- **Instructor Questions**: Probe understanding with targeted questions

### Summative Assessment Options

#### Option 1: Activity Performance (Automated)
- **Metric**: Alignment with expert recommendations (0-100%)
- **Threshold**: 70% for proficiency
- **Weight**: 40% of total assessment

#### Option 2: Written Reflection (Manual Review)
- **Prompt**: "Explain your metric selection strategy and how it addresses the business scenario's key objectives."
- **Rubric**: See detailed rubric in assessment-rubric.md
- **Weight**: 60% of total assessment

#### Option 3: Scenario Analysis (Extended Activity)
- **Task**: Analyze a new scenario not used in the activity
- **Deliverable**: 300-word justification for metric selection
- **Assessment**: Demonstrated understanding of business-metric alignment

### Grading Rubric (Summary)

| Criterion | Excellent (A) | Proficient (B) | Developing (C) | Beginning (D) |
|-----------|---------------|----------------|----------------|---------------|
| Business Analysis | Identifies all key objectives and stakeholder needs | Identifies most key objectives | Identifies some objectives | Limited objective identification |
| Metric Knowledge | Demonstrates deep understanding of all metric categories | Shows good understanding of most metrics | Basic understanding of some metrics | Limited metric knowledge |
| Alignment Reasoning | Clearly connects metrics to specific business objectives | Makes good connections with minor gaps | Some logical connections made | Weak or unclear connections |
| Expert Comparison | Thoughtfully analyzes differences and learns from expert perspective | Compares selections and shows some learning | Basic comparison with limited insight | Minimal engagement with expert feedback |

## Extensions and Variations

### For Advanced Students
1. **Custom Scenario Creation**: Have students create their own business scenarios with expert recommendations
2. **Metric Weight Assignment**: Add a component where students assign importance weights to selected metrics
3. **Implementation Planning**: Extend activity to include how metrics would be measured and monitored
4. **Stakeholder Role-Play**: Assign different stakeholder perspectives and have students defend their selections

### For Struggling Students
1. **Guided Practice**: Provide partially completed examples with explanation
2. **Scenario Simplification**: Use more straightforward business contexts
3. **Metric Categories**: Start with selecting categories before specific metrics
4. **Peer Support**: Pair with stronger students for collaborative learning

### Industry-Specific Adaptations
- **Healthcare**: Focus on safety, accuracy, and transparency metrics
- **Finance**: Emphasize compliance, fairness, and transparency
- **Education**: Highlight engagement, personalization, and fairness
- **E-commerce**: Stress persuasiveness, product knowledge, and customer satisfaction

## Common Misconceptions and Corrections

### Misconception 1: "More metrics is always better"
**Correction**: Explain the overhead of evaluation and the importance of focused measurement. Use analogy of KPIs in business - too many dilute focus.

### Misconception 2: "Technical metrics are more important than business metrics"
**Correction**: Emphasize that technical quality enables business success, but business metrics determine actual success. Both are necessary.

### Misconception 3: "One-size-fits-all metric selection"
**Correction**: Demonstrate how the same AI application (e.g., chatbot) needs different metrics for different contexts (sales vs. support vs. education).

### Misconception 4: "Expert recommendations are always right"
**Correction**: Explain that experts make choices based on experience and priorities, but different valid approaches exist. The key is having good reasoning.

## Technology Integration Tips

### Learning Management System Integration
- Export student selections for gradebook integration
- Use discussion forums for extended reflection
- Create analytics dashboards to track class performance patterns
- Set up automatic progress tracking

### Blended Learning Approaches
- Use activity as in-class practice after online lecture
- Assign as homework with in-class debriefing
- Incorporate into group projects as evaluation planning phase
- Use for flipped classroom pre-assessment

### Accessibility Considerations
- Ensure screen reader compatibility for visually impaired students
- Provide keyboard navigation for motor accessibility
- Use high-contrast colors for visual clarity
- Offer text-to-speech options for reading support

## Professional Development Connection

### Industry Relevance
This activity directly prepares students for:
- AI project evaluation planning
- Stakeholder communication about AI metrics
- AI system monitoring and optimization
- Business-technology alignment roles

### Career Skills Developed
- **Analytical Thinking**: Breaking down complex business requirements
- **Communication**: Explaining technical concepts to business stakeholders
- **Decision Making**: Choosing between multiple valid options with trade-offs
- **Systems Thinking**: Understanding how evaluation fits into larger AI deployment

### Certification Alignment
Activity aligns with:
- Azure AI Engineer Associate certification objectives
- AI Ethics and Governance certifications
- Project Management Professional (PMP) evaluation planning
- Business Analysis certification requirements

## Instructor Resources

### Additional Reading
- Azure AI Foundry evaluation documentation
- Industry case studies of AI evaluation successes and failures
- Research papers on AI metrics and business alignment
- Best practices guides for AI project evaluation

### Support Materials
- Video tutorials for activity setup and troubleshooting
- Webinar recordings of expert discussions on metric selection
- Templates for creating custom scenarios
- Examples of successful implementations in different industries

### Community Resources
- Instructor discussion forum for sharing experiences
- Student work showcase for exemplary responses
- Industry partner network for real-world scenario validation
- Regular updates on Azure AI Foundry metric additions and changes

This instructor guide provides comprehensive support for facilitating an effective learning experience that bridges technical AI evaluation concepts with real-world business applications.