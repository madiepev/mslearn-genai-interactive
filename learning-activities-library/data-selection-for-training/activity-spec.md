# Data Selection for Training Activity

## üìã Activity Overview

**Activity Type**: Dataset Curation and Quality Assessment  
**Duration**: 20-25 minutes  
**Difficulty**: Intermediate  
**Learning Modality**: Interactive selection with criteria-based evaluation

## üéØ Learning Objectives

By completing this data selection activity, learners will be able to:

1. **Apply quality criteria** to evaluate conversation examples for training datasets
2. **Identify exemplary responses** that demonstrate desired AI behavior patterns
3. **Make systematic decisions** about data inclusion based on multiple quality dimensions
4. **Understand the impact** of training data quality on model performance
5. **Balance dataset composition** to ensure comprehensive coverage of scenarios

## üìö Prerequisites

- Understanding of AI training concepts
- Familiarity with conversation quality metrics
- Basic knowledge of fine-tuning processes
- Understanding of customer service best practices

## üîß Activity Structure

### Phase 1: Criteria Understanding (5 minutes)
- Review selection criteria (politeness, clarity, appropriateness)
- Understand target behavior for fine-tuning
- Learn about dataset balance considerations

### Phase 2: Conversation Evaluation (15 minutes)
- Review 6-8 conversation examples across different scenarios
- Apply quality criteria to each conversation
- Select conversations that meet training standards
- Balance dataset across different support types

### Phase 3: Dataset Review & Validation (5 minutes)
- Review selected conversations as a complete dataset
- Ensure diversity and quality standards
- Receive feedback on selection decisions

## üìä Selection Criteria

### Primary Quality Metrics
1. **Politeness Level** - Professional, respectful tone throughout
2. **Clarity Level** - Clear, understandable communication
3. **Response Quality** - Helpful, accurate, and appropriate responses
4. **Scenario Coverage** - Diverse situation types for comprehensive training

### Selection Standards
- **High Politeness**: Consistently courteous and professional
- **High Clarity**: Easy to understand with clear next steps
- **Appropriate Responses**: Contextually suitable and helpful
- **Diverse Scenarios**: Mix of support types (orders, refunds, technical, billing)

## üé® Visual Design Requirements

### Selection Interface
- Grid layout showing multiple conversations simultaneously
- Clear conversation cards with user/AI exchanges
- Quality indicators (badges/tags) for each conversation
- Selection status indicators (selected/not selected counter)
- Progress tracking (X of Y conversations selected)

### Conversation Cards
- Clean chat-style formatting
- User messages (blue, right-aligned)
- AI responses (green/gray, left-aligned)
- Quality level badges (High/Medium/Low for each criterion)
- Selection checkbox or toggle button
- Scenario type labels (Customer Support, Technical Support, etc.)

### Feedback Interface
- Dataset composition summary
- Quality distribution analysis
- Selection accuracy scoring
- Recommendations for improvement

## üìÅ Required Assets

### Sample Conversations
- **Excellent Examples**: High quality across all metrics
- **Mixed Quality**: Good in some areas, weaker in others
- **Poor Examples**: Clear quality issues to avoid
- **Diverse Scenarios**: Order inquiries, refunds, technical issues, billing questions, account access, service complaints

### Quality Indicators
- Predefined quality assessments for each conversation
- Expert selections for comparison
- Detailed rubrics for each criterion

### Training Objectives
- Clear definition of desired AI behavior
- Examples of target responses
- Anti-patterns to avoid in training data

## üîÑ Interaction Flow

1. **Present Training Goal**: Show objective for fine-tuning (e.g., "polite and clear customer service")
2. **Display Conversations**: Present 6-8 conversation options with quality indicators
3. **Guided Selection**: Learner selects 2-3 conversations that best meet training criteria
4. **Real-time Feedback**: Show selection progress and dataset balance
5. **Final Review**: Evaluate selected dataset for quality and diversity
6. **Expert Comparison**: Compare selections with expert recommendations

## üìà Assessment Criteria

### Mastery Indicators
- Accurate identification of high-quality training examples
- Appropriate balance of scenario types in selected dataset
- Understanding of quality trade-offs in selection decisions
- Ability to justify selection rationale

### Scoring Rubric
- **Excellent (90-100%)**: All selections align with expert choices, balanced dataset
- **Good (70-89%)**: Most selections appropriate with minor quality gaps
- **Needs Improvement (<70%)**: Significant gaps in quality recognition or dataset balance

## üõ†Ô∏è Technical Implementation

### Required Components
- Conversation display grid
- Multi-criteria quality indicators
- Selection tracking system
- Dataset composition analyzer
- Progress and feedback displays

### Data Structure
```javascript
{
  trainingGoal: "Create polite and clear customer service responses",
  conversations: [
    {
      id: "conv-1",
      scenario: "Order Delay Inquiry",
      userMessage: "...",
      aiResponse: "...",
      qualityScores: {
        politeness: "high",
        clarity: "high",
        appropriateness: "high"
      },
      selected: false,
      expertRecommended: true
    }
  ],
  selectionCriteria: {
    targetCount: 3,
    requiredQuality: ["high politeness", "high clarity"],
    diversityRequirement: "mixed scenarios"
  }
}
```

## üìù Content Templates

See `content-templates/` folder for:
- Training objective statements
- Conversation examples with quality assessments
- Selection rubrics and guidelines
- Feedback message templates

## üîó Integration Guidelines

### HTML Structure
```html
<div class="data-selection-activity">
  <div class="training-objective"><!-- Goal statement --></div>
  <div class="selection-progress"><!-- Progress indicator --></div>
  <div class="conversations-grid"><!-- Conversation cards --></div>
  <div class="dataset-summary"><!-- Selection overview --></div>
  <div class="feedback-section"><!-- Results and recommendations --></div>
</div>
```

### CSS Classes
- `.conversation-card` - Individual conversation display
- `.quality-indicators` - Badges showing quality levels
- `.selection-status` - Visual selection state
- `.dataset-composition` - Summary display
- `.expert-feedback` - Comparison results

### JavaScript Events
- `conversationSelected(id, selected)` - Handle selection toggle
- `validateDataset()` - Check selection criteria
- `submitSelections()` - Process final dataset
- `showFeedback(results)` - Display expert comparison

## üéØ Customization Options

### Content Variables
- Training objectives and goals
- Conversation scenarios and complexity
- Quality criteria and thresholds
- Target dataset size and composition

### Difficulty Levels
- **Beginner**: Clear quality differences, obvious good/bad examples
- **Intermediate**: Subtle quality variations, trade-off decisions
- **Advanced**: Complex scenarios, nuanced quality assessments

### Domain Adaptation
- **Customer Service**: Focus on politeness and helpfulness
- **Technical Support**: Emphasize clarity and accuracy
- **Educational**: Prioritize encouragement and understanding
- **Healthcare**: Stress empathy and precise information