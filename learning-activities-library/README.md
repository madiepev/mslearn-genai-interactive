# Learning Activities Library

This library contains reusable learning activity specifications and assets that can be integrated into hands-on exercises. Each activity is designed to be modular, configurable, and easy to implement.

## Available Activities

### 1. AI Configuration Evaluation
**Purpose**: Practice evaluating different AI model configurations and response quality using structured criteria.

**Skills Developed**:
- AI model configuration assessment
- Response quality evaluation using ACRUE framework (Accurate, Complete, Relevant, Useful, Exceptional)
- Comparative analysis of AI performance
- Decision-making with multiple evaluation criteria

**Activity Structure**:
- Interactive configuration panels with dark theme interface
- Multi-dimensional rating systems for responses
- Expert comparison and feedback mechanisms
- Scenario-based evaluation practice

**Use Cases**: Model selection, configuration optimization, response quality assessment

### 2. Data Selection for Training
**Purpose**: Learn to curate high-quality training datasets by evaluating conversation examples and selecting appropriate data for AI fine-tuning.

**Skills Developed**:
- Training data quality assessment
- Conversation analysis and selection criteria application
- Dataset curation for specific AI objectives
- Quality vs. quantity decision-making in data selection

**Activity Structure**:
- Conversation cards with quality indicators
- Multi-criteria selection interface
- Expert curation comparison
- Quality rubric application

**Use Cases**: Fine-tuning dataset preparation, conversation data curation, training data quality control

### 3. Evaluation Criteria Selection
**Purpose**: Develop skills in selecting appropriate Azure AI Foundry evaluation metrics based on business scenarios and objectives.

**Skills Developed**:
- Business scenario analysis for AI evaluation needs
- Azure AI Foundry metrics knowledge and application
- Strategic alignment of evaluation criteria with business objectives
- Stakeholder perspective consideration in metric selection

**Activity Structure**:
- Business scenario analysis interface
- Azure AI Foundry metrics library with detailed descriptions
- Expert recommendation comparison system
- Reflection and reasoning documentation tools

**Use Cases**: AI evaluation planning, business-technical alignment, stakeholder communication about AI metrics

---

## üîß How to Use This Library

1. **Browse Activities**: Each folder contains a complete activity specification
2. **Review Specs**: Check the `activity-spec.md` file for detailed requirements
3. **Use Assets**: Copy the provided templates and sample data
4. **Integrate**: Follow the integration guide to add to your hands-on exercise

## üìù Activity Structure

Each activity includes:
- `activity-spec.md` - Complete activity specification
- `assets/` - Sample data, templates, and resources
- `integration-guide.md` - Instructions for implementation
- `content-templates/` - Markdown templates for content developers

## ‚ûï Contributing New Activities

To add a new learning activity:
1. Create a new folder with descriptive name
2. Follow the standard structure (see existing activities)
3. Include all required specification files
4. Add entry to this README

---

## üéØ Design Principles

- **Modular**: Each activity is self-contained
- **Configurable**: Easy to customize for different contexts
- **Content-Developer Friendly**: Clear markdown-based content editing
- **Close-Ended**: Measurable learning outcomes with clear assessment criteria
- **Interactive**: Engaging hands-on learning experiences